{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing relevant packages\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import nltk\n",
    "import random\n",
    "from random import shuffle\n",
    "from nltk.metrics.scores import (precision, recall)\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the function that extracts the last letter and last 2 letters of the names \n",
    "## as features\n",
    "\n",
    "def gender_features(word): ## accuracy of 0.858 with European names only, 0.742 with Maori inc.\n",
    "    return {'suffix1': word[-1:],\n",
    "            'suffix2': word[-2:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782\n",
      "0.75177304964539\n",
      "Most Informative Features\n",
      "                 suffix1 = 'd'                 M : F      =      9.4 : 1.0\n",
      "                 suffix1 = 'a'                 F : M      =      9.3 : 1.0\n",
      "                 suffix2 = 'in'                M : F      =      5.1 : 1.0\n",
      "                 suffix1 = 's'                 M : F      =      5.1 : 1.0\n",
      "                 suffix2 = 'ie'                F : M      =      4.7 : 1.0\n",
      "                 suffix2 = 'on'                M : F      =      4.4 : 1.0\n",
      "                 suffix2 = 'is'                M : F      =      4.3 : 1.0\n",
      "                 suffix2 = 'an'                M : F      =      3.9 : 1.0\n",
      "                 suffix2 = 'ra'                F : M      =      3.9 : 1.0\n",
      "                 suffix2 = 'te'                F : M      =      3.7 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Classification algorithm\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Starting block \"\"\"\n",
    "\n",
    "    # Extract the data sets\n",
    "    labeled_names = (pd.read_csv(\"Names_Combined.csv\")[['Name', 'Gender', 'Ethnicity']])\n",
    "    \n",
    "    print(len(labeled_names))  # 782 names\n",
    "    \n",
    "     # Shuffle the names in the list\n",
    "    labeled_names = labeled_names.sample(frac=1)\n",
    "    \n",
    "    # Extract features from dataset\n",
    "    feature_sets = [(gender_features(labeled_names.Name.iloc[i]),\n",
    "                                   labeled_names.Gender.iloc[i]) \n",
    "                    for i in range(0, len(labeled_names))]\n",
    "    \n",
    "    #Extract ethnicity from dataset\n",
    "    feature_sets_ethnicity = [labeled_names.Ethnicity.iloc[i] \n",
    "                              for i in range(0, len(labeled_names))]\n",
    "    \n",
    "    # Divide the feature sets into training and test sets\n",
    "    train_set, test_set = feature_sets[:500], feature_sets[500:]\n",
    "    \n",
    "    train_ethnicity, test_ethnicity = feature_sets_ethnicity[:500], feature_sets_ethnicity[500:]\n",
    "    \n",
    "    # Train the naiveBayes classifier\n",
    "    classifierNB = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    # Test the accuracy of the classifier on the test data\n",
    "    print(nltk.classify.accuracy(classifierNB, test_set))# returns 0.78 for now\n",
    "\n",
    "    # Examine classifier to determine which feature is most effective for\n",
    "    # distinguishing the name's gender\n",
    "    print(classifierNB.show_most_informative_features(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Turning test set into a DataFrame from a list  \n",
    "test_df = pd.DataFrame(test_set)\n",
    "\n",
    "## Extracting the column of actual genders from the test df\n",
    "y_test = test_df[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114  41]\n",
      " [ 29  98]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          F       0.80      0.74      0.77       155\n",
      "          M       0.71      0.77      0.74       127\n",
      "\n",
      "avg / total       0.76      0.75      0.75       282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Predict the genders of the test dataset and save these in a list. \n",
    "y_pred = []\n",
    "\n",
    "for i in range(0, 282):\n",
    "        y_pred.append(classifierNB.classify(test_df.iloc[i,0]))\n",
    "\n",
    "## Print a confusion matrix of actual vs predicted genders for the test dataset. \n",
    "print(confusion_matrix(y_test, y_pred)) ## Accuracy of 77%\n",
    "\n",
    "## Get a classification report - precision, recall\n",
    "print(classification_report(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            features gender ethnicity\n",
      "0  {'suffix1': 'r', 'suffix2': 'er'}      M  European\n",
      "1  {'suffix1': 'a', 'suffix2': 'la'}      F  European\n",
      "2  {'suffix1': 'o', 'suffix2': 'lo'}      M  European\n",
      "3  {'suffix1': 'l', 'suffix2': 'll'}      M  European\n",
      "4  {'suffix1': 'y', 'suffix2': 'ey'}      F  European\n"
     ]
    }
   ],
   "source": [
    "## Add ethnicity information to test dataset\n",
    "test_ethnicity_df = pd.DataFrame(test_ethnicity)\n",
    "\n",
    "ethnicities_test_df = test_df.merge(right = test_ethnicity_df, left_index = True, right_index=True)\n",
    "ethnicities_test_df.columns = ['features', 'gender', 'ethnicity']\n",
    "print(ethnicities_test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split test set up by ethnicity\n",
    "maori_test_subset = ethnicities_test_df[ethnicities_test_df.ethnicity == 'Maori'][['features', 'gender']]\n",
    "\n",
    "european_test_subset = ethnicities_test_df[ethnicities_test_df.ethnicity == 'European'][['features', 'gender']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "print(len(maori_test_subset)) \n",
    "print(len(european_test_subset)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  2]\n",
      " [ 7  5]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          F       0.65      0.87      0.74        15\n",
      "          M       0.71      0.42      0.53        12\n",
      "\n",
      "avg / total       0.68      0.67      0.65        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Predict the genders of the Maori test dataset and save these in a list. \n",
    "\n",
    "y_maori_test = maori_test_subset['gender']\n",
    "\n",
    "y_maori_pred = []\n",
    "\n",
    "for i in range(0, len(maori_test_subset)):\n",
    "        y_maori_pred.append(classifierNB.classify(maori_test_subset.iloc[i,0]))\n",
    "\n",
    "## Print a confusion matrix of actual vs predicted genders for the Maori test dataset. \n",
    "print(confusion_matrix(y_maori_test, y_maori_pred)) \n",
    "\n",
    "## Get classification report - precision, recall etc. \n",
    "print(classification_report(y_maori_test, y_maori_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101  39]\n",
      " [ 22  93]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          F       0.82      0.72      0.77       140\n",
      "          M       0.70      0.81      0.75       115\n",
      "\n",
      "avg / total       0.77      0.76      0.76       255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## predict the genders of the european test dataset and save these in a list. \n",
    "y_european_test = european_test_subset['gender']\n",
    "\n",
    "y_european_pred = []\n",
    "\n",
    "for i in range(0, len(european_test_subset)):\n",
    "        y_european_pred.append(classifierNB.classify(european_test_subset.iloc[i,0]))\n",
    "\n",
    "## print a confusion matrix of actual vs predicted genders for the european test dataset. \n",
    "print(confusion_matrix(y_european_test, y_european_pred)) ## Accuracy of 73%\n",
    "\n",
    "## get precision, recall etc. \n",
    "print(classification_report(y_european_test, y_european_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
